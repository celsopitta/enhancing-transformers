model:
    target: enhancing.modules.stage1.vitvqgan.ViTVQ
    params:
        image_key: image
        path: None # /fsx/thuna/enhancing-transformers/experiments/imagenet_vitvq_base/21072022_064447/ckpt/imagenet_vitvq_base-epoch=08.ckpt
        hparams:
            image_size: 256
            patch_size: 8
            dim: 768
            depth: 12
            heads: 12
            mlp_dim: 3072
        qparams:
            embed_dim: 32
            n_embed: 8192
        loss:
            target: enhancing.losses.vqperceptual.VQLPIPSWithDiscriminator
            params:
                loglaplace_weight: 0.0
                loggaussian_weight: 1.0
                perceptual_weight: 0.1
                adversarial_weight: 0.1

dataset:
    target: enhancing.dataloader.DataModuleFromConfig
    params:
        batch_size: 8
        num_workers: 4
        train:
            target: enhancing.dataloader.imagenet.ImageNetTrain
            params:
                root: /mnt/datasets/imagenet2012
                resolution: 256

        validation:
            target: enhancing.dataloader.imagenet.ImageNetValidation
            params:
                root: /mnt/datasets/imagenet2012
                resolution: 256